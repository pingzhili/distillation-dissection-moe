{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-04T10:08:25.311943Z",
     "start_time": "2025-03-04T10:08:23.803192Z"
    }
   },
   "source": [
    "from pydoc import resolve\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from transformers import PreTrainedTokenizerBase, AutoTokenizer"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T10:12:49.036134Z",
     "start_time": "2025-03-04T10:12:48.098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/OLMoE-1B-7B-0125-SFT\", trust_remote_code=True)\n",
    "examples = {\n",
    "    \"question\": [\"Is 123 a prime?\"],\n",
    "    \"response\": [\"No, 123 is not a prime number. It can be factored as 3 × 41.\"]\n",
    "}"
   ],
   "id": "25ab71c2beb0c6a6",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T10:09:25.769884Z",
     "start_time": "2025-03-04T10:09:25.761029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_general_chat_template(\n",
    "        question: str,\n",
    "        tokenizer: PreTrainedTokenizerBase,\n",
    "        response: Optional[str] = None,\n",
    "):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    if response is None:\n",
    "        return tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "    else:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return tokenizer.apply_chat_template(messages, add_generation_prompt=False, tokenize=False)\n",
    "\n",
    "\n",
    "def sft_olmoe_train_batch_preprocess_fn(\n",
    "        examples: Dict[str, List[Any]],\n",
    "        tokenizer: PreTrainedTokenizerBase,\n",
    "):\n",
    "    if tokenizer is None:\n",
    "        raise ValueError(\"Tokenizer is required for SFT training.\")\n",
    "\n",
    "    # 1. apply general chat template to each example\n",
    "    all_chat_texts = []\n",
    "\n",
    "    for question, response in zip(examples[\"question\"], examples[\"response\"]):\n",
    "        chat_text = apply_general_chat_template(question, response=response, tokenizer=tokenizer)\n",
    "        all_chat_texts.append(chat_text)\n",
    "\n",
    "    # 2. Tokenize the chat\n",
    "    all_input_ids = []\n",
    "    all_attention_masks = []\n",
    "    all_labels = []\n",
    "\n",
    "    for chat_text in all_chat_texts:\n",
    "        encoded = tokenizer(chat_text, padding=False, truncation=True)\n",
    "        input_ids = encoded[\"input_ids\"]\n",
    "        attention_mask = encoded[\"attention_mask\"]\n",
    "\n",
    "        # 3. Only apply LM loss on the assistant's response & \"<|endoftext|>\"\n",
    "        labels = [-100] * len(input_ids)\n",
    "\n",
    "        assistant_token_id = tokenizer(\"<|assistant|>\", add_special_tokens=False)[\"input_ids\"]\n",
    "        end_token_id = tokenizer.convert_tokens_to_ids(\"<|endoftext|>\")\n",
    "\n",
    "        pos_assistant = -1\n",
    "        pos_end_after_response = -1\n",
    "\n",
    "        i = 0\n",
    "        while i <= len(input_ids) - len(assistant_token_id):\n",
    "            matched = True\n",
    "            for j in range(len(assistant_token_id)):\n",
    "                if input_ids[i + j] != assistant_token_id[j]:\n",
    "                    matched = False\n",
    "                    break\n",
    "\n",
    "            if matched:\n",
    "                pos_assistant = i + len(assistant_token_id) - 1\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "        if pos_assistant != -1:\n",
    "            for i in range(pos_assistant + 1, len(input_ids)):\n",
    "                if input_ids[i] == end_token_id:\n",
    "                    pos_end_after_response = i\n",
    "                    break\n",
    "\n",
    "        if pos_assistant != -1 and pos_end_after_response != -1:\n",
    "            for i in range(pos_assistant + 1, pos_end_after_response):\n",
    "                labels[i] = input_ids[i]\n",
    "\n",
    "        all_input_ids.append(input_ids)\n",
    "        all_attention_masks.append(attention_mask)\n",
    "        all_labels.append(labels)\n",
    "        print(pos_assistant, pos_end_after_response)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": all_input_ids,\n",
    "        \"attention_mask\": all_attention_masks,\n",
    "        \"labels\": all_labels\n",
    "    }"
   ],
   "id": "850f6b144359d86e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T10:09:38.669134Z",
     "start_time": "2025-03-04T10:09:38.664425Z"
    }
   },
   "cell_type": "code",
   "source": "results = sft_olmoe_train_batch_preprocess_fn(examples, tokenizer)",
   "id": "ad08806d4a8a1193",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 -1\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T10:09:38.906667Z",
     "start_time": "2025-03-04T10:09:38.901468Z"
    }
   },
   "cell_type": "code",
   "source": "results",
   "id": "b6262f8b199cfaf6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[50279,\n",
       "   29,\n",
       "   93,\n",
       "   10394,\n",
       "   49651,\n",
       "   187,\n",
       "   1394,\n",
       "   403,\n",
       "   247,\n",
       "   9371,\n",
       "   13372,\n",
       "   15,\n",
       "   187,\n",
       "   29,\n",
       "   93,\n",
       "   4537,\n",
       "   49651,\n",
       "   187,\n",
       "   2513,\n",
       "   15567,\n",
       "   247,\n",
       "   4335,\n",
       "   32,\n",
       "   187,\n",
       "   29,\n",
       "   93,\n",
       "   515,\n",
       "   5567,\n",
       "   49651,\n",
       "   187,\n",
       "   2302,\n",
       "   13,\n",
       "   15567,\n",
       "   310,\n",
       "   417,\n",
       "   247,\n",
       "   4335,\n",
       "   1180,\n",
       "   15,\n",
       "   733,\n",
       "   476,\n",
       "   320,\n",
       "   958,\n",
       "   2149,\n",
       "   347,\n",
       "   495,\n",
       "   6806,\n",
       "   7609,\n",
       "   15,\n",
       "   50279]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]],\n",
       " 'labels': [[-100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100]]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T10:12:52.469119Z",
     "start_time": "2025-03-04T10:12:52.465396Z"
    }
   },
   "cell_type": "code",
   "source": "apply_general_chat_template(\"Is 123 a prime?\", tokenizer, \"No, 123 is not a prime number. It can be factored as 3 × 41.\")",
   "id": "d651a78e65244687",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|||IP_ADDRESS|||<|system|>\\nYou are a helpful assistant.\\n<|user|>\\nIs 123 a prime?\\n<|assistant|>\\nNo, 123 is not a prime number. It can be factored as 3 × 41.|||IP_ADDRESS|||'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T10:11:54.750726Z",
     "start_time": "2025-03-04T10:11:54.747697Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer",
   "id": "31c0fef58c6312da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXTokenizerFast(name_or_path='allenai/OLMoE-1B-7B-0125-Instruct', vocab_size=50254, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '|||IP_ADDRESS|||', 'eos_token': '|||IP_ADDRESS|||', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<|padding|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50254: AddedToken(\"                        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50255: AddedToken(\"                       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50256: AddedToken(\"                      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50257: AddedToken(\"                     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50258: AddedToken(\"                    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50259: AddedToken(\"                   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50260: AddedToken(\"                  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50261: AddedToken(\"                 \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50262: AddedToken(\"                \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50263: AddedToken(\"               \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50264: AddedToken(\"              \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50265: AddedToken(\"             \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50266: AddedToken(\"            \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50267: AddedToken(\"           \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50268: AddedToken(\"          \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50269: AddedToken(\"         \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50270: AddedToken(\"        \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50271: AddedToken(\"       \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50272: AddedToken(\"      \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50273: AddedToken(\"     \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50274: AddedToken(\"    \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50275: AddedToken(\"   \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50276: AddedToken(\"  \", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50277: AddedToken(\"|||EMAIL_ADDRESS|||\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50278: AddedToken(\"|||PHONE_NUMBER|||\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "\t50279: AddedToken(\"|||IP_ADDRESS|||\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t50280: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-04T10:13:35.298162Z",
     "start_time": "2025-03-04T10:13:35.295506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Is 123 a prime?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"No, 123 is not a prime number. It can be factored as 3 × 41.\"}\n",
    "]"
   ],
   "id": "9fe2cdf731c62ce9",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d3b6723ef15a72c9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
